syntax = "proto3";
package datadozer;
import "google/protobuf/wrappers.proto";

option csharp_namespace = "Datadozer.Models";
option cc_enable_arenas = true;
option java_multiple_files = true;
option java_package = "org.datadozer.models";
option java_outer_classname = "DataDozerModel";
option objc_class_prefix = "DZM";

// Data type of the fields
enum FieldDataType {
    TEXT = 0;
    KEYWORD = 1;
    INTEGER_POINT = 3;
    LONG_PONT = 4;
    FLOAT_POINT = 5;
    DOUBLE_POINT = 6;
    BINARY_POINT = 7;
    DATE = 8;
    DATE_TIME = 9;
    STORED_ONLY = 10;
    IP4 = 11;
    IP6 = 12;
    LAT_LONG = 13;
    BOOLEAN = 14;
    TIMESTAMP = 15;
}

// Corresponds to Lucene Index version. There will always be a default
// codec associated with each index version.
enum IndexVersion {
    DATA_DOZER_1A = 0;
}

// A Directory is a flat list of files. Files may be written once, when
// they are created. Once a file is created it may only be opened for
// read, or deleted. Random access is permitted both when reading and
// writing.
enum DirectoryType {
    MEMORY_MAPPED = 0;
    RAM = 1;
    FILE_SYSTEM = 2;
}

// Similarity defines the components of scoring. Similarity determines how
// engine weights terms. FlexSearch interacts with Similarity at both index-time
// and query-time.
enum Similarity {
    BM25 = 0;
    TFIDF = 1;
}

// Operation status of service call. It will always be set for an response message.
enum OperationStatus {
    SUCCESS = 0;
    FAILURE = 1;
}

message KeyValue {
    string key = 1;
    string value = 2;
}

// Represents an operational message returned from the operation. This can be used to
// represent both success and failure messages.
message OperationMessage {
    // The actual message returned by the operation.
    string message = 1;

    // Details of the operation as key value pairs. This is more efficient that using
    // a map as we don't care about the retrieval speed. We don't have to pay the cost
    // of repeated hashing and will be more memory efficient.
    repeated KeyValue details = 2;

    // Operation Code associated with the message.
    OperationStatus status = 3;
}

// Tokenizer breaks up a stream of text into tokens, where each token is a sub-sequence
// of the characters in the text. An analyzer is aware of the fields it is configured
// for, but a tokenizer is not.
message Tokenizer {
    // Name of the tokenizer
    string tokenizer_name = 1;

    // Key value pair to be used to configure object's properties.
    map<string, string> parameters = 2;
}

// Filters consume input and produce a stream of tokens. In most cases a filter looks
// at each token in the stream sequentially and decides whether to pass it along,
// replace it or discard it. A filter may also do more complex analysis by looking
// ahead to consider multiple tokens at once, although this is less common.
message Filter {
    // Name of the filter
    string filter_name = 1;

    // Key value pair to be used to configure object's properties.
    map<string, string> parameters = 2;
}

// An analyzer examines the text of fields and generates a token stream.
message Analyzer {
    // Name of the analyzer
    string analyzer_name = 1;

    // Tokenizer associated with the analyzer
    Tokenizer tokenizer = 2;

    // FIiters associated with the analyzer
    repeated Filter filters = 3;
}

// Allows to control various Index Shards related writerSettings.
message ShardConfiguration {
    // Total number of shards to be present in the given index.
    int32 shard_count = 1;
}

// Overrall status of the Index
enum IndexStatus {
    OFFLINE = 0;
    OPENING = 1;
    LOCAL_RECOVERY = 2;
    REMOTE_RECOVERY = 3;
    ONLINE_MASTER = 4;
    ONLINE_SLAVE = 5;
    ONLINE_REPLICA = 6;
    CLOSING = 7;
}

// Configuration option for stored fields.
enum CompressionMode {
    // Trade compression ratio for retrieval speed.
    OPTIMIZE_FOR_SPEED = 0;

    // Trade retrieval speed for compression ratio.
    OPTIMIZE_FOR_SIZE = 1;
}

// Allows to control various Index related writerSettings.
message IndexConfiguration {
    // The amount of time in seconds that FlexSearch should wait before
    // committing changes to the disk. This is only used if no commits have
    // happened in the set time period otherwise CommitEveryNFlushes takes
    // care of commits
    google.protobuf.Int32Value commit_time_seconds = 1;

    // The amount of time in milliseconds that FlexSearch should wait before
    // reopening index reader. This helps in keeping writing and real time
    // aspects of the engine separate.
    google.protobuf.Int32Value refresh_time_milliseconds = 2;

    ShardConfiguration shard_configuration = 3;

    // Determines whether to commit first before closing an index
    google.protobuf.BoolValue commit_on_close = 4;

    // Determines whether to enable auto commit functionality or not
    google.protobuf.BoolValue auto_commit = 5;

    // Determines whether to clear all transaction logs before closing an
    // index. This setting is for advance use and should be left to default.
    google.protobuf.BoolValue delete_logs_on_close = 6;

    // A Directory is a flat list of files. Files may be written once, when
    // they are created. Once a file is created it may only be opened for
    // read, or deleted. Random access is permitted both when reading and
    // writing.
    DirectoryType directory_type = 7;

    // The default maximum time to wait for a write lock (in milliseconds).
    google.protobuf.Int32Value default_write_lock_timeout_milliseconds = 8;

    // Determines the amount of RAM that may be used for buffering added
    // documents and deletions before they are flushed to the Directory.
    google.protobuf.Int32Value ram_buffer_size_mb = 9;

    // The number of buffered added documents that will trigger a flush if
    // enabled.
    google.protobuf.Int32Value max_buffered_docs = 10;

    // Determines whether to enable auto refresh or not
    google.protobuf.BoolValue auto_refresh = 11;

    // Corresponds to Lucene Index version. There will always be a default
    // codec associated with each index version.
    IndexVersion index_version = 12;

    // Signifies if the index supports reading back of indexed data.
    google.protobuf.BoolValue allow_reads = 13;

    // Signifies if the index supports modification of data.
    google.protobuf.BoolValue allow_writes = 14;

    // Default similarity for the index
    Similarity default_similarity = 15;

    // Information about merges, deletes and a
    // message when maxFieldLength is reached will be printed
    // to index specific log file.
    google.protobuf.BoolValue verbose_mode = 16;

    // If enabled then the user can use optimistic locking to update a
    // given record. This will use the modify index fields to provide
    // optimistic lock.
    // Note: There is a slight performance penalty of using this feature
    // as the id of the records will be saved in an internal cache.
    google.protobuf.BoolValue support_optimistic_concurrency = 17;

    // Data type that will be used by the ID key
    IdKeyDataType id_key_datatype = 18;

    // If Id fields should support sorting. This is also required for
    // range query generation.
    google.protobuf.BoolValue allow_sort_on_id_field = 19;

    // Compression configuration option for stored fields.
    CompressionMode compression_mode = 20;
}

// A single indexable fields
message Field {
    // Name of the fields
    string field_name = 1;

    // Field data type
    FieldDataType data_type = 2;

    // Enable fields sorting
    google.protobuf.BoolValue allow_sort = 3;

    // Analyzer to be used during indexing
    google.protobuf.StringValue index_analyzer = 4;

    // Analyzer to be used during searching
    google.protobuf.StringValue search_analyzer = 5;

    // Similarity for the fields
    Similarity similarity = 6;

    // Allow multiple values for the field
    google.protobuf.BoolValue multivalued = 7;
}

message Index {
    // Name of the index
    string index_name = 1;

    // Fields present in the index
    repeated Field fields = 2;

    // Index configuration writerSettings
    IndexConfiguration index_configuration = 3;

    // Represents if an Index is active or not?
    google.protobuf.BoolValue active = 4;

    // Shard configuration
    ShardConfiguration shardConfiguration = 5;
}

message IntegerValues {
    repeated int32 values = 1;
}

message LongValues {
    repeated int64 values = 1;
}

message FloatValues {
    repeated float values = 1;
}

message DoubleValues {
    repeated float values = 1;
}

message StringValues {
    repeated string values = 1;
}

// FieldValue for a fields in a document
message FieldValue {
    oneof value {
        string string_value = 1;
        int32 integer_value = 2;
        int64 long_value = 3;
        bytes bytes_value = 4;
        float float_value = 5;
        double double_value = 6;
        bool bool_value = 7;
        IntegerValues integer_values = 8;
        FloatValues float_values = 9;
        StringValues string_values = 10;
        LongValues long_values = 11;
        DoubleValues double_values = 12;
    }
}

// Data type to be used by the ID Key
enum IdKeyDataType {
    STRING = 0;
    INTEGER = 1;
    LONG = 2;
    BYTES = 3;
}

// Additional information associated with a document which is only populated when
// search results are returned.
message SearchResultProperties {
    // Represents the time at which the document was last indexed
    int64 timestamp = 8;

    // The score associated with the document. This will only be used when
    // documents are returned from a Search Query.
    float score = 9;

    // highlights
}

// A document represents the basic unit of information which can be added or
// retrieved from the index. A document consists of several fields. A fields represents
// the actual data to be indexed. In database analogy an index can be considered as
// a table while a document is a row of that table. Like a table a Datadozer document
// requires a fix schema and all fields should have a fields type.
message Document {

    // Name of the index to which the document belongs
    string index_name = 1;

    // The unique id of the document. This can be specified using the FieldValue but only
    // a subset of data type is supported by the ID fields. The data type of the id fields
    // is defined by the IdFieldType property in IndexConfiguration.
    FieldValue id = 2;

    // Represents the operation number associated with the operation in the global order
    // of the operations. This allows causal ordering of the events. A documents with a lower
    // ModifyIndex can be assumed to be modified before another with a higher number. ModifyIndex
    // is used for optimistic concurrency control.
    int64 modify_index = 5;

    // Since we are not taking the fields names as part of values we use this hash to identifty
    // the order in which fields are passed to the server.
    string field_order_hash = 6;

    // Field Values associated with the document
    map<string, FieldValue> fields = 7;

    // Additional information associated with a document which is only populated when
    // search results are returned.
    SearchResultProperties properties = 8;
}

// Types of transaction log enteries
enum TransactionLogEntryType {
    DOC_CREATE = 0;
    DOC_UPDATE = 1;
    DOC_DELETE = 2;
    DOC_BULKDELETE = 3;
    INDEX_CREATE = 4;
    INDEX_UPDATE = 5;
    INDEX_DELETE = 6;
    INDEX_CLEAR = 7;
    REVERT_DOC = 8;
}

// TransactionLogEntryHeader defines the header level properties for a transaction. It
// is fixed size which enables use to travese a file quickly as we don't have to detect the
// size of the files. This will also help in case of transaction log curroption.
message TransactionLogEntryHeader {
    int64 modify_index = 1;
    int32 index_id = 2;
    TransactionLogEntryType entry_type = 3;
    int32 data_location = 4;
    int32 message_size = 5;
    int32 file_id = 6;
}

// A transaction is the minimum unit of work in DataDozer. The message is written to
// the physical medium before applying the transaction. This provides durability in
// the envent of failure.
message TransactionLogEntry {
    TransactionLogEntryHeader header = 1;
    bytes data = 2;
}